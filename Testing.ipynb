{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80f253c1-b509-4d2a-b246-1fd2ca0ee324",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "\n",
    "df = pd.read_csv('Company_Rating_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9cd5d09-652a-42e6-af66-99062b6e1d8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Company Name', 'Number of Reviews', 'Average Salary', 'Job Openings',\n",
       "       'Location Website', 'Global Size', 'Industry', 'Description',\n",
       "       'Company Rating', 'Company Webpage', 'Headquarters', 'Global Size 2',\n",
       "       'Company Location', 'Company Ownership Type', 'Year Founded',\n",
       "       'Est Yearly Revenue', 'Industry 2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# choose relevant columns \n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da6c4c18-e830-4936-9d99-5ce25177695f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for and remove records with default values ('Unknown', -1)\n",
    "df = df[df['Global Size'] != -1] # 883 additional\n",
    "df = df[df['Global Size'] != 'Unknown']\n",
    "df = df[df['Company Rating'] != -1] # 144 additional\n",
    "df = df[df['Company Ownership Type'] != 'Unknown'] # 27 additional/\n",
    "df = df[df['Company Ownership Type'] != -1] # 27 additional\n",
    "df = df[df['Year Founded'] != -1] # 1,053 additional\n",
    "df = df[df['Est Yearly Revenue'] != 'Unknown / Non-Applicable'] # 1,430 additional\n",
    "df = df[df['Est Yearly Revenue'] != -1] # 1,430 additional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3c76ad1-d0d8-41ef-bca0-e7e3e9ced16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://github.com/jordanwheeler7/capstone-crop-yield/blob/main/crop_yield.ipynb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import plotly.express as px\n",
    "import statsmodels.api as sm\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from IPython.display import display\n",
    "from math import sqrt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1615e5-e0be-4234-8623-b040a58b78cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the features and target variable\n",
    "features = ['Global Size','Est Yearly Revenue','Year Founded']\n",
    "X = df_yield[features]\n",
    "y = df_yield['Company Rating']\n",
    "\n",
    "# Create a column transformer to apply OneHotEncoder to the 'Item' column\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('onehot', OneHotEncoder(), ['Item'])\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Create a pipeline with the preprocessor and the LinearRegression model\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', LinearRegression())\n",
    "])\n",
    "\n",
    "# Fit the pipeline to the data\n",
    "pipeline.fit(X, y)\n",
    "\n",
    "# Get the feature names after one-hot encoding\n",
    "ohe = preprocessor.named_transformers_['onehot']\n",
    "feature_names = ohe.get_feature_names_out(input_features=['Item'])\n",
    "other_features = ['avg_temp', 'Pesticides', 'avg_precipitation']\n",
    "all_features = list(feature_names) + other_features\n",
    "\n",
    "# Get the coefficients for the features from the model\n",
    "coefficients = pipeline.named_steps['model'].coef_\n",
    "\n",
    "# Print out the features with their coefficients\n",
    "feature_coefficients = dict(zip(all_features, coefficients))\n",
    "for feature, coef in feature_coefficients.items():\n",
    "    print(f'{feature}: {coef}')\n",
    "\n",
    "# Print out the intercept\n",
    "intercept = pipeline.named_steps['model'].intercept_\n",
    "print(f'Intercept: {intercept}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db94ee6a-3a0c-4dc5-bada-7e6c693ad151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the features and target variable\n",
    "categorical_features = ['Item']\n",
    "numerical_features = ['avg_temp', 'Pesticides', 'avg_precipitation']\n",
    "features = numerical_features + categorical_features\n",
    "X = df_yield[features]\n",
    "y = df_yield['Yield']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a column transformer to apply OneHotEncoder to the 'Item' column\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('onehot', OneHotEncoder(), categorical_features)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Define polynomial features with interaction only\n",
    "poly_features = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
    "\n",
    "# Create a pipeline with the preprocessor, polynomial features, and a linear regression model\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('polynomial_features', poly_features),\n",
    "    ('linear_regression', LinearRegression())\n",
    "])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate on training data\n",
    "y_train_pred = pipeline.predict(X_train)\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "rmse_train =  np.sqrt(mse_train)\n",
    "mae_train = mean_absolute_error(y_train, y_train_pred)\n",
    "\n",
    "# Predict and evaluate on testing data\n",
    "y_test_pred = pipeline.predict(X_test)\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "rmse_test =  np.sqrt(mse_test)\n",
    "mae_test = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "# Print the results for training data\n",
    "print(f'Training Data - R-squared: {r2_train}, Mean Squared Error: {mse_train}, Root Mean Squared Error: {rmse_train}, Mean Absolute Error: {mae_train}')\n",
    "\n",
    "# Print the results for testing data\n",
    "print(f'Testing Data - R-squared: {r2_test}, Mean Squared Error: {mse_test}, Root Mean Squared Error: {rmse_test}, Mean Absolute Error: {mae_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4212f7e2-fb0e-43a4-93a7-c7bfeba0d466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding Categorical Features\n",
    "categorical_features = ['Global Size', 'Est Yearly Revenue']\n",
    "numerical_features = ['Year Founded']\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('onehot', OneHotEncoder(), categorical_features)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "X = df_rating[categorical_features + numerical_features]\n",
    "y = df_rating['Company Rating']\n",
    "\n",
    "# # Splitting data\n",
    "# X_transformed = preprocessor.fit_transform(X)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_transformed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# std_scaler = StandardScaler(with_mean=False)\n",
    "# X_train_scale = std_scaler.fit_transform(X_train)\n",
    "# # Scale test data for evaluation\n",
    "# X_test_scale = std_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd0dd60-4040-4b17-a4fc-abce694faf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/jordanwheeler7/capstone-crop-yield/blob/main/crop_yield.ipynb\n",
    "# Random Forest Best Parameters for my data: {'max_depth': 10, 'min_samples_split': 10, 'n_estimators': 300}\n",
    "rf = RandomForestRegressor(max_depth=10, min_samples_split=10, n_estimators=300, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_train_pred = rf.predict(X_train)\n",
    "y_test_pred = rf.predict(X_test)\n",
    "\n",
    "# R-squared\n",
    "rf_train_score = r2_score(y_train, y_train_pred)\n",
    "rf_test_score = r2_score(y_test, y_test_pred)\n",
    "\n",
    "# Mean Absolute Error (MAE)\n",
    "rf_train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "rf_test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "# Mean Squared Error (MSE)\n",
    "rf_train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "rf_test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "# Root Mean Squared Error (RMSE)\n",
    "rf_train_rmse = np.sqrt(rf_train_mse)\n",
    "rf_test_rmse = np.sqrt(rf_test_mse)\n",
    "\n",
    "# Printing the results\n",
    "print(f\"Random Forest - Training R-squared: {rf_train_score}, Testing R-squared: {rf_test_score}\")\n",
    "print(f\"Random Forest - Training MAE: {rf_train_mae}, Testing MAE: {rf_test_mae}\")\n",
    "print(f\"Random Forest - Training MSE: {rf_train_mse}, Testing MSE: {rf_test_mse}\")\n",
    "print(f\"Random Forest - Training RMSE: {rf_train_rmse}, Testing RMSE: {rf_test_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa4355b-1acf-4dc7-8e1d-1de6da48fa78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/jordanwheeler7/capstone-crop-yield/blob/main/crop_yield.ipynb\n",
    "# Gradient Boosting Best Parameters for my data: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 300}\n",
    "gb = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "gb.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_train_pred = gb.predict(X_train)\n",
    "y_test_pred = gb.predict(X_test)\n",
    "\n",
    "# R-squared\n",
    "gb_train_score = r2_score(y_train, y_train_pred)\n",
    "gb_test_score = r2_score(y_test, y_test_pred)\n",
    "\n",
    "# Mean Absolute Error (MAE)\n",
    "gb_train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "gb_test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "# Mean Squared Error (MSE)\n",
    "gb_train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "gb_test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "# Root Mean Squared Error (RMSE)\n",
    "gb_train_rmse = np.sqrt(gb_train_mse)\n",
    "gb_test_rmse = np.sqrt(gb_test_mse)\n",
    "\n",
    "# Printing the results\n",
    "print(f\"Gradient Boosting - Training R-squared: {gb_train_score}, Testing R-squared: {gb_test_score}\")\n",
    "print(f\"Gradient Boosting - Training MAE: {gb_train_mae}, Testing MAE: {gb_test_mae}\")\n",
    "print(f\"Gradient Boosting - Training MSE: {gb_train_mse}, Testing MSE: {gb_test_mse}\")\n",
    "print(f\"Gradient Boosting - Training RMSE: {gb_train_rmse}, Testing RMSE: {gb_test_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1486abe6-da18-4953-853b-21f7c04cc461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/jordanwheeler7/capstone-crop-yield/blob/main/crop_yield.ipynb\n",
    "# Decision Tree Best Parameters for my data: {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 10}\n",
    "dt = DecisionTreeRegressor(max_depth=10, min_samples_leaf=4, min_samples_split=10, random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_train_pred = dt.predict(X_train)\n",
    "y_test_pred = dt.predict(X_test)\n",
    "\n",
    "# R-squared\n",
    "dt_train_score = r2_score(y_train, y_train_pred)\n",
    "dt_test_score = r2_score(y_test, y_test_pred)\n",
    "\n",
    "# Mean Absolute Error (MAE)\n",
    "dt_train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "dt_test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "# Mean Squared Error (MSE)\n",
    "dt_train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "dt_test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "# Root Mean Squared Error (RMSE)\n",
    "dt_train_rmse = np.sqrt(dt_train_mse)\n",
    "dt_test_rmse = np.sqrt(dt_test_mse)\n",
    "\n",
    "# Printing the results\n",
    "print(f\"Decision Tree - Training R-squared: {dt_train_score}, Testing R-squared: {dt_test_score}\")\n",
    "print(f\"Decision Tree - Training MAE: {dt_train_mae}, Testing MAE: {dt_test_mae}\")\n",
    "print(f\"Decision Tree - Training MSE: {dt_train_mse}, Testing MSE: {dt_test_mse}\")\n",
    "print(f\"Decision Tree - Training RMSE: {dt_train_rmse}, Testing RMSE: {dt_test_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e32693-6fe9-45f1-a3e3-47800e9ee0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/jordanwheeler7/capstone-crop-yield/blob/main/crop_yield.ipynb\n",
    "# K-Nearest Neighbors Best Parameters: {'algorithm': 'auto', 'n_neighbors': 7, 'weights': 'uniform'}\n",
    "knn = KNeighborsRegressor(algorithm= 'auto', n_neighbors=7, weights= 'distance')\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_train_pred = knn.predict(X_train)\n",
    "y_test_pred = knn.predict(X_test)\n",
    "\n",
    "# R-squared\n",
    "knn_train_score = r2_score(y_train, y_train_pred)\n",
    "knn_test_score = r2_score(y_test, y_test_pred)\n",
    "\n",
    "# Mean Absolute Error (MAE)\n",
    "knn_train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "knn_test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "# Mean Squared Error (MSE)\n",
    "knn_train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "knn_test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "# Root Mean Squared Error (RMSE)\n",
    "knn_train_rmse = np.sqrt(knn_train_mse)\n",
    "knn_test_rmse = np.sqrt(knn_test_mse)\n",
    "\n",
    "# Printing the results\n",
    "print(f\"K-Nearest Neighbors - Training R-squared: {knn_train_score}, Testing R-squared: {knn_test_score}\")\n",
    "print(f\"K-Nearest Neighbors - Training MAE: {knn_train_mae}, Testing MAE: {knn_test_mae}\")\n",
    "print(f\"K-Nearest Neighbors - Training MSE: {knn_train_mse}, Testing MSE: {knn_test_mse}\")\n",
    "print(f\"K-Nearest Neighbors - Training RMSE: {knn_train_rmse}, Testing RMSE: {knn_test_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3bd7f6-6495-4062-8733-5483030d5d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/jordanwheeler7/capstone-crop-yield/blob/main/crop_yield.ipynb\n",
    "# Buidling the Neural Network Model\n",
    "nn_model = MLPRegressor(hidden_layer_sizes=(250), max_iter=1000, random_state=42)\n",
    "\n",
    "# Training the model\n",
    "nn_model.fit(X_train, y_train)\n",
    "\n",
    "# Predicting and evaluating the model\n",
    "y_train_pred = nn_model.predict(X_train)\n",
    "y_test_pred = nn_model.predict(X_test)\n",
    "\n",
    "# R-squared\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "# Mean Absolute Error (MAE)\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "# Mean Squared Error (MSE)\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "# Root Mean Squared Error (RMSE)\n",
    "train_rmse = np.sqrt(train_mse)\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "\n",
    "# Printing the results\n",
    "print(f\"Neural Network - Training R-squared: {train_r2}, Testing R-squared: {test_r2}\")\n",
    "print(f\"Neural Network - Training MAE: {train_mae}, Testing MAE: {test_mae}\")\n",
    "print(f\"Neural Network - Training MSE: {train_mse}, Testing MSE: {test_mse}\")\n",
    "print(f\"Neural Network - Training RMSE: {train_rmse}, Testing RMSE: {test_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75506a7-1e42-4539-b34e-c8504a619aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/jordanwheeler7/capstone-crop-yield/blob/main/crop_yield.ipynb\n",
    "\"\"\"\n",
    "\n",
    "To utilize this block, uncomment def perform_grid_search.\n",
    "The code is commented out due to the extinsive time and\n",
    "resources required to run the GridSearch.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def perform_grid_search(estimator, param_grid, model_name, X_train, y_train, X_test, y_test):\n",
    "    grid_search = GridSearchCV(estimator, param_grid, scoring='neg_mean_absolute_error')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    best_estimator = grid_search.best_estimator_\n",
    "    predictions = best_estimator.predict(X_test)\n",
    "\n",
    "    best_mae = -grid_search.best_score_  # neg_mean_absolute_error is returned negative by GridSearchCV\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    rmse = sqrt(mse)\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "\n",
    "    print(f\"{model_name} Best Parameters: {grid_search.best_params_}\")\n",
    "    print(f\"{model_name} Best MAE: {best_mae}\")\n",
    "    print(f\"{model_name} Best MSE: {mse}\")\n",
    "    print(f\"{model_name} Best RMSE: {rmse}\")\n",
    "    print(f\"{model_name} Best R-squared: {r2}\")\n",
    "\n",
    "\n",
    "# Random Forest Grid Search\n",
    "rf_params = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "perform_grid_search(RandomForestRegressor(random_state=42), rf_params, 'Random Forest', X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Gradient Boosting Grid Search\n",
    "gb_params = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 10]\n",
    "}\n",
    "perform_grid_search(GradientBoostingRegressor(random_state=42), gb_params, 'Gradient Boosting', X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Decision Tree Grid Search\n",
    "dt_params = {\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "perform_grid_search(DecisionTreeRegressor(random_state=42), dt_params, 'Decision Tree', X_train, y_train, X_test, y_test)\n",
    "\n",
    "# K-Nearest Neighbors Grid Search\n",
    "knn_params = {\n",
    "    'n_neighbors': [3, 5, 7],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "}\n",
    "perform_grid_search(KNeighborsRegressor(), knn_params, 'K-Nearest Neighbors', X_train, y_train, X_test, y_test)\n",
    "\n",
    "# # Neural Network Grid Search\n",
    "# nn_params = {\n",
    "#     'hidden_layer_sizes': [(50,), (100,), (50,50), (100,100)],\n",
    "#     'activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "#     'solver': ['lbfgs', 'sgd', 'adam'],\n",
    "#     'alpha': [0.0001, 0.001, 0.01, 0.1],\n",
    "#     'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "#     'max_iter': [200, 500, 1000]\n",
    "# }\n",
    "\n",
    "# Perform grid search for MLPRegressor\n",
    "perform_grid_search(MLPRegressor(random_state=42), nn_params, 'Neural Network', X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3444ad33-3f28-4736-9e05-dab683d08293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring in One Hot Encoder Features\n",
    "ohe_feature_names = preprocessor.named_transformers_['onehot'].get_feature_names_out(categorical_features)\n",
    "\n",
    "# Combine the one-hot encoded feature names with the numerical feature names\n",
    "full_feature_names = np.concatenate((ohe_feature_names, numerical_features))\n",
    "\n",
    "# Ensure the length of `full_feature_names` matches the number of features in `feature_importance`\n",
    "assert len(full_feature_names) == len(feature_importance), \"Mismatch in the number of features and importances.\"\n",
    "\n",
    "# Sort the feature importances and get the indices for the top features\n",
    "sorted_indices = np.argsort(feature_importance)[::-1]\n",
    "top_n = min(len(full_feature_names), 10)\n",
    "sorted_indices_top = sorted_indices[:top_n]\n",
    "\n",
    "# Plot the feature importances\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(range(top_n), feature_importance[sorted_indices_top], align='center')\n",
    "plt.yticks(range(top_n), full_feature_names[sorted_indices_top], fontsize=12) \n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Top Feature Importances for Gradient Boosting Model')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0fe73e-71bb-425f-8bd5-50e912e8e34e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fa87c3-ac13-4e75-8021-e383be0f6cb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
